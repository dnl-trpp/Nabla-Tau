{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T8q8XSqi9OOb",
    "outputId": "23a9e2a3-406e-4969-f88e-1eb89a7cceef"
   },
   "outputs": [],
   "source": [
    "drive_folder = \"Machine_Unlearning_Drive/Cifar100Results/\"\n",
    "\n",
    "ssd_folder = \"SSD/\"\n",
    "\n",
    "scrub_folder = \"SCRUB/\"\n",
    "\n",
    "github_folder = \"Machine_Unlearning/\"\n",
    "\n",
    "!pip install scikit-learn torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LqDmZw6P9RpF",
    "outputId": "78782c79-dd9c-40b2-98b6-323e9cf53270"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, model_selection\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import json\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "from Machine_Unlearning.Metrics.metrics import *\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device:\", DEVICE.upper())\n",
    "\n",
    "def seed_everything(seed):\n",
    "  RNG = torch.Generator().manual_seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  return RNG\n",
    "\n",
    "SEED = 44\n",
    "SPLIT = 0.15\n",
    "RNG = seed_everything(SEED)\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "id": "FAerSXaSB_Rl",
    "outputId": "338593db-deee-4c85-8580-902469390f7d"
   },
   "outputs": [],
   "source": [
    "import torch as trch\n",
    "import torchvision.datasets as dts\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torchvision.models import VGG16_Weights\n",
    "from torchvision.utils import make_grid\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plot\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "DEVICE = \"cuda\" if trch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device:\", DEVICE.upper())\n",
    "\n",
    "\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "                         transforms.RandomCrop(32, padding=4),\n",
    "                         transforms.RandomHorizontalFlip(),\n",
    "                         transforms.ToTensor(), transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "                         transforms.ToTensor(),\n",
    "                         transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))\n",
    "        ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_set = dts.CIFAR100(root='./data', download=True, train=True, transform=train_transform)\n",
    "train_loader = trch.utils.data.DataLoader(train_set, batch_size=128, shuffle=True)\n",
    "\n",
    "test_set = dts.CIFAR100(root='./data', download=True, train=False, transform=test_transform)\n",
    "test_loader = trch.utils.data.DataLoader(test_set, batch_size=128, shuffle=False)\n",
    "\n",
    "\n",
    "GEN1 = torch.Generator().manual_seed(42)\n",
    "retain_set, forget_set = torch.utils.data.random_split(train_set,[1-SPLIT,SPLIT],GEN1)\n",
    "RNG = seed_everything(1337)\n",
    "forget_loader = torch.utils.data.DataLoader(\n",
    "    forget_set, batch_size=256, shuffle=True, num_workers=2 , generator=RNG\n",
    ")\n",
    "retain_loader = torch.utils.data.DataLoader(\n",
    "    retain_set, batch_size=256, shuffle=True, num_workers=2, generator=RNG\n",
    ")\n",
    "\n",
    "\n",
    "cmodel = models.resnet18(weights=None, num_classes=100)\n",
    "cmodel = cmodel.to(DEVICE)\n",
    "\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "plt.title(\"Sample images from Caltech101 dataset\")\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kDSlsKVCmhJA"
   },
   "outputs": [],
   "source": [
    "def accuracy(net, loader):\n",
    "    \"\"\"Return accuracy on a dataset given by the data loader.\"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i,(inputs, targets) in enumerate(loader):\n",
    "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "        #print(i)\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2MobXMN19g68"
   },
   "outputs": [],
   "source": [
    "def readout(model,name):\n",
    "  RNG = seed_everything(SEED)\n",
    "  test_entropies = compute_entropy(model, test_loader)\n",
    "  retain_entropies = compute_entropy(model, retain_loader)\n",
    "  forget_entropies = compute_entropy(model, forget_loader)\n",
    "\n",
    "\n",
    "  results[f\"test_entropies_{name}\"] = test_entropies.tolist()\n",
    "  results[f\"retain_entropies_{name}\"] = retain_entropies.tolist()\n",
    "  results[f\"forget_entropies_{name}\"] = forget_entropies.tolist()\n",
    "\n",
    "  test_losses = compute_losses(model, test_loader)\n",
    "  retain_losses = compute_losses(model, retain_loader)\n",
    "  forget_losses = compute_losses(model, forget_loader)\n",
    "\n",
    "  results[f\"test_losses_{name}\"] = test_losses.tolist()\n",
    "  results[f\"retain_losses_{name}\"] = retain_losses.tolist()\n",
    "  results[f\"forget_losses_{name}\"] = forget_losses.tolist()\n",
    "\n",
    "  # Since we have more forget losses than test losses, sub-sample them, to have a class-balanced dataset.\n",
    "  gen = np.random.default_rng(1)\n",
    "  if len(test_losses) > len(forget_losses):\n",
    "    gen.shuffle(test_losses)\n",
    "    test_losses = test_losses[: len(forget_losses)]\n",
    "  else:\n",
    "    gen.shuffle(forget_losses)\n",
    "    forget_losses = forget_losses[: len(test_losses)]\n",
    "    # make sure we have a balanced dataset for the MIA\n",
    "  assert len(test_losses) == len(forget_losses)\n",
    "\n",
    "  samples_mia = np.concatenate((test_losses, forget_losses)).reshape((-1, 1))\n",
    "  labels_mia = [0] * len(test_losses) + [1] * len(forget_losses)\n",
    "\n",
    "  mia_scores = simple_mia(samples_mia, labels_mia)\n",
    "\n",
    "  print(\n",
    "      f\"The MIA has an accuracy of {mia_scores.mean():.3f} on forgotten vs unseen images\"\n",
    "  )\n",
    "\n",
    "  results[f\"MIA_losses_{name}\"] = mia_scores.mean()\n",
    "\n",
    "  gen = np.random.default_rng(1)\n",
    "  if len(test_entropies) > len(forget_entropies):\n",
    "    gen.shuffle(test_entropies)\n",
    "    test_entropies = test_entropies[: len(forget_entropies)]\n",
    "  else:\n",
    "    gen.shuffle(forget_entropies)\n",
    "    forget_entropies = forget_entropies[: len(test_entropies)]\n",
    "    # make sure we have a balanced dataset for the MIA\n",
    "  assert len(test_entropies) == len(forget_entropies)\n",
    "\n",
    "  samples_mia = np.concatenate((test_entropies, forget_entropies)).reshape((-1, 1))\n",
    "  labels_mia = [0] * len(test_entropies) + [1] * len(forget_entropies)\n",
    "\n",
    "  mia_scores = simple_mia(samples_mia, labels_mia)\n",
    "\n",
    "  print(\n",
    "      f\"The MIA has an accuracy of {mia_scores.mean():.3f} on forgotten vs unseen images\"\n",
    "  )\n",
    "\n",
    "  results[f\"MIA_entropies_{name}\"] = mia_scores.mean()\n",
    "\n",
    "  results[f\"train_accuracy_{name}\"] = accuracy(model, retain_loader)\n",
    "  results[f\"test_accuracy_{name}\"] = accuracy(model, test_loader)\n",
    "  results[f\"forget_accuracy_{name}\"] = accuracy(model, forget_loader)\n",
    "\n",
    "  print(\"Train acc:\"+ str(results[f\"train_accuracy_{name}\"]))\n",
    "  print(\"Test acc:\"+ str(results[f\"test_accuracy_{name}\"]))\n",
    "  print(\"Forget acc:\" +str(results[f\"forget_accuracy_{name}\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QkLy-EqWEupw",
    "outputId": "a9ed5743-333f-4459-843f-02ca65f5f245"
   },
   "outputs": [],
   "source": [
    "#This model has been trained using SGD with a learning rate of 0.1, momentum of 0.9 and weight decay of 5e-4.\n",
    "\n",
    "numepchs = 50\n",
    "lr = 0.1\n",
    "criter = nn.CrossEntropyLoss()\n",
    "optim = trch.optim.SGD(cmodel.parameters(), lr=lr,momentum = 0.9, weight_decay=5e-4)\n",
    "scheduler = trch.optim.lr_scheduler.LinearLR(optim, start_factor=1.0, end_factor=0.001, total_iters=numepchs)\n",
    "nttlstps = len(retain_loader)\n",
    "cmodel.train()\n",
    "for epoch in range(numepchs):\n",
    "    for x, (imgs, lbls) in enumerate(retain_loader):\n",
    "         imgs , lbls = imgs.to(DEVICE), lbls.to(DEVICE)\n",
    "         #imgs = imgs.reshape(-1, 28*28)\n",
    "\n",
    "\n",
    "         outp = cmodel(imgs)\n",
    "         losses = criter(outp, lbls)\n",
    "\n",
    "         optim.zero_grad()\n",
    "         losses.backward()\n",
    "         optim.step()\n",
    "         if x % 100 == 0:\n",
    "           print (f'Epochs [{epoch+1}/{numepchs}], Step[{x+1}/{nttlstps}], Losses: {losses.item():.4f}')\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NAMDeTLa9ok7",
    "outputId": "1a27b486-4d88-4021-b08e-c1b3b2e31427"
   },
   "outputs": [],
   "source": [
    "readout(cmodel,\"retrained\")\n",
    "#with open(drive_folder+f\"results_Cifar100_SPLIT_{int(SPLIT*100)}%_SEED_{SEED}_retrained.json\", 'w') as fout:\n",
    "#  json.dump(results, fout)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
